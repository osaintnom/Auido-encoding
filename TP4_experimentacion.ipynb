{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Inicializacion e importe de librerias"
      ],
      "metadata": {
        "id": "SUZxclEkTOcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hICEx-EqQxWy",
        "outputId": "290963ea-ae43-4e2d-fcbe-d3fd1507a6bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pydub scikit-learn wandb torchview torchviz graphviz matplotlib tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz8wyXsMQuBE",
        "outputId": "f32abf91-a29f-49ac-cf11-d4ee2d075465"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.35.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu118)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dij9PodZQyeA",
        "outputId": "a7c1b584-2d99-4e94-e94a-8063f93b4712"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.35.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSdBL2673KUX",
        "outputId": "10714ecb-9dd2-4e29-ec8b-1c35cf3518bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchaudio) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchaudio) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchaudio\n",
        "!pip install  pydub\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bfbad9b2649155692b5f97a49a43c0eeb66dff4a"
      ],
      "metadata": {
        "id": "9uyYQX44SlKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\n",
        "    'mps:0' if torch.backends.mps.is_available() else 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    )\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMyj1ug7Q8gw",
        "outputId": "9a037fae-75f6-43f8-aaa8-4267bd160e3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# TP4: Encodeador de música\n",
        "\n",
        "\n",
        "\n",
        "## Orden de pasos\n",
        "\n",
        "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
        "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
        "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "3. Visualización de los archivos\n",
        "4. Clasificación\n",
        "5. Evaluación\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lAR3tiGci2-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASE"
      ],
      "metadata": {
        "id": "qApAl-j1TbdJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "rt4FEe853KUX"
      },
      "outputs": [],
      "source": [
        "project_name='Music_genre_classification'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5G8mTE-5zM"
      },
      "source": [
        "### 2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "q5AUydgIxfwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b720c402-25cf-4913-de81-e831c2829223"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_dir es el path donde pusimos la carpeta genres. \"'//content/drive/MyDrive/Materias/TD6 - Inteligencia Artificial/TPs/2023/TP4/genres/'\" es un ejemplo. Modificar."
      ],
      "metadata": {
        "id": "qYLOe3isiV0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7kYMlPdYrzCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc6bffd-6a4c-49ec-984b-0abe805de4c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rock',\n",
              " 'pop',\n",
              " 'hiphop',\n",
              " 'disco',\n",
              " 'blues',\n",
              " 'reggae',\n",
              " 'country',\n",
              " 'metal',\n",
              " 'classical',\n",
              " 'jazz']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import os\n",
        "data_dir='/content/drive/MyDrive/genres_5sec/'\n",
        "list_files=os.listdir(data_dir)\n",
        "classes=[]\n",
        "for file in list_files:\n",
        "  name='{}/{}'.format(data_dir,file)\n",
        "  if os.path.isdir(name):\n",
        "    classes.append(file)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samplerate=22050\n",
        "def parse_genres(fname):\n",
        "    parts = fname.split('/')[-1].split('.')[0]\n",
        "    return parts #' '.join(parts[0])\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.files =[]\n",
        "        for c in classes:\n",
        "          self.files = self.files + [fname for fname in os.listdir(os.path.join(root,c)) if fname.endswith('.wav')]\n",
        "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
        "        #self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "            fname = self.files[i]\n",
        "\n",
        "            #img = self.transform(open_image(fpath))\n",
        "            genre = parse_genres(fname)\n",
        "            fpath = os.path.join(self.root,genre, fname)\n",
        "            class_idx = self.classes.index(genre)\n",
        "            audio = torchaudio.load(fpath)[0]\n",
        "\n",
        "            spectogram = tt.Spectrogram(\n",
        "                n_fft=1024,\n",
        "            )(audio)\n",
        "\n",
        "            # MelSpectrogram tt.MelSpectrogram(sample_rate=samplerate, n_fft=1024, hop_length=512, n_mels=128)(audio)\n",
        "            # mel_spectogram = tt.MelSpectrogram(sample_rate=samplerate, n_fft=1024, hop_length=200, n_mels=201)(audio)\n",
        "\n",
        "            hop_length=432\n",
        "            n_mels=256\n",
        "            n_fft = 2*(n_mels - 1)\n",
        "\n",
        "            mel_spectogram = tt.MelSpectrogram(sample_rate=samplerate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)(audio)\n",
        "\n",
        "            return audio, spectogram, mel_spectogram, class_idx\n",
        "\n",
        "    def __repr__(self):\n",
        "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
        "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
        "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
        "        # List classes\n",
        "        fmt_str += '    Classes: {}\\n'.format(self.classes)\n",
        "        return fmt_str\n",
        "dataset = MusicDataset(data_dir)"
      ],
      "metadata": {
        "id": "GJxZV04XZtnP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "lKYr-sEfWzvp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos en train y val"
      ],
      "metadata": {
        "id": "Zgc_yVIq8Cbq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-dr5Qhgk5sjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a72fde6-8456-4e5f-cc56-4244ed2fe7c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(790, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "val_size = 100\n",
        "test_size = 100\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds),len(val_ds),len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wBHjbBoo5sG1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 20\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,1, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio, spectogram, mel_spectogram, class_idx = train_dl.dataset[12]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(audio.size(),samplerate,class_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkMIU-MAHTM9",
        "outputId": "dcaf8856-f510-46db-d76f-b9c716ec89b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of waveform torch.Size([1, 110250]), sample rate with 22050, label is 5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Visualización de los archivos"
      ],
      "metadata": {
        "id": "H_VFArTDXy5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "waveform,spectogram, mel_spectogram,label= dataset[0]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))\n",
        "# label = 9 es rock"
      ],
      "metadata": {
        "id": "qIGGF2t9c-QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "specgram=tt.Spectrogram()(waveform)\n",
        "print(\"shape of spectogram {}\".format(specgram.size()))\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(specgram.log2()[0,:,:].numpy(),cmap='magma')"
      ],
      "metadata": {
        "id": "MjLl0uSfc_RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Waveform: {}\\n\".format(waveform))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(waveform.t().numpy())"
      ],
      "metadata": {
        "id": "EAVh9vlpdDHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escuchamos el espectograma con la librería de audio"
      ],
      "metadata": {
        "id": "fWvDQtm6dE2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(waveform,rate=samplerate)"
      ],
      "metadata": {
        "id": "gvGzuWBFdGfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "specgram.size()"
      ],
      "metadata": {
        "id": "JXxwYapDdHxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "val_size = 100\n",
        "test_size = 100\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds),len(val_ds),len(test_ds)"
      ],
      "metadata": {
        "id": "aAJncPPWXmFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 20\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,1, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "Vn7l6fspX6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnHDpoYttX8"
      },
      "source": [
        "### 4. Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pkfBRO910vu3"
      },
      "outputs": [],
      "source": [
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryss1Hhm3KUf",
        "outputId": "4b0f87b2-3a71-4a67-eb89-7b6f07437772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M5(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(80,), stride=(16,))\n",
            "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
            "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
            "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
            "  (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Number of parameters: 25290\n"
          ]
        }
      ],
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cnn = M5(n_input=1, n_output=len(classes))\n",
        "cnn.to(device)\n",
        "print(cnn)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(cnn)\n",
        "print(\"Number of parameters: %s\" % n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTnjUZU_3oou",
        "outputId": "f8f9fe3e-02ae-4fca-b002-677ab31ddcf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "f6cJrYPk8V8J",
        "outputId": "89556ba7-45c4-4dbf-f1cf-3d31fd9e60f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [1/30], Train loss: 2.1018\n",
            "Epoch: [1/30], Valid loss: 2.1315, Valid accuracy: 0.2000\n",
            "Saving the best model at 0 epochs!\n",
            "Epoch: [2/30], Train loss: 1.8713\n",
            "Epoch: [2/30], Valid loss: 1.8169, Valid accuracy: 0.3400\n",
            "Saving the best model at 1 epochs!\n",
            "Epoch: [3/30], Train loss: 1.7702\n",
            "Epoch: [3/30], Valid loss: 1.7404, Valid accuracy: 0.4300\n",
            "Saving the best model at 2 epochs!\n",
            "Epoch: [4/30], Train loss: 1.6608\n",
            "Epoch: [4/30], Valid loss: 1.6589, Valid accuracy: 0.4900\n",
            "Saving the best model at 3 epochs!\n",
            "Epoch: [5/30], Train loss: 1.6254\n",
            "Epoch: [5/30], Valid loss: 1.7023, Valid accuracy: 0.4000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cc4ac9cc1151>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mwav\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gc\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0005)\n",
        "valid_losses = []\n",
        "num_epochs = 30\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect() #importante para ir liberando memoria ram\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    # Train\n",
        "    cnn.train()\n",
        "    for wav, genre_index in train_dl:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        wav=wav.to(device)\n",
        "        genre_index =torch.as_tensor(genre_index).to(device)\n",
        "\n",
        "        # Forward\n",
        "        out = cnn(wav)\n",
        "        #M5\n",
        "        loss = F.nll_loss(out.squeeze(), genre_index)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        del wav #importante para ir liberando memoria ram\n",
        "        del genre_index #importante para ir liberando memoria ram\n",
        "        del loss #importante para ir liberando memoria ram\n",
        "        del out  #importante para ir liberando memoria ram\n",
        "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
        "\n",
        "    # Validation\n",
        "    cnn.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    losses = []\n",
        "    correct =0\n",
        "    for wav, genre_index in valid_dl:\n",
        "        #print(wav, genre, index)\n",
        "        wav = wav.to(device)\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        out = cnn(wav)\n",
        "        #M5\n",
        "        loss = F.nll_loss(out.squeeze(), genre_index)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        #M5\n",
        "        pred= out.argmax(dim=-1).flatten()\n",
        "        # append labels and predictions\n",
        "        correct += pred.eq(genre_index).sum().item()\n",
        "        y_true.extend(genre_index)\n",
        "        y_pred.extend(pred)\n",
        "        del wav #importante para ir liberando memoria ram\n",
        "        del genre_index #importante para ir liberando memoria ram\n",
        "        del loss #importante para ir liberando memoria ram\n",
        "        del out  #importante para ir liberando memoria ram\n",
        "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "    accuracy =correct/ len(valid_dl.dataset)\n",
        "    valid_loss = np.mean(losses)\n",
        "    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n",
        "\n",
        "    # Save model\n",
        "    valid_losses.append(valid_loss.item())\n",
        "    if np.argmin(valid_losses) == epoch:\n",
        "        print('Saving the best model at %d epochs!' % epoch)\n",
        "        torch.save(cnn.state_dict(), 'best_model.ckpt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFwYdlWxCN0M"
      },
      "source": [
        "\n",
        "\n",
        "### 5. Evaluación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6RFD17nU81b"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(test_ds,1,shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Pqtx-D0zAwa"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "S = torch.load('best_model.ckpt')\n",
        "cnn.load_state_dict(S)\n",
        "print('loaded!')\n",
        "\n",
        "# Run evaluation\n",
        "cnn.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for  wav, _, spectogram, genre_index in test_dl:\n",
        "        wav = wav.to(device)\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        out = cnn(wav)\n",
        "\n",
        "        pred= out.argmax(dim=-1).flatten()\n",
        "        # append labels and predictions\n",
        "        correct += pred.eq(genre_index).sum().item()\n",
        "        y_true.extend(genre_index)\n",
        "        y_pred.extend(pred)\n",
        "\n",
        "accuracy =correct/ len(test_dl.dataset)\n",
        "print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA6O4xauAZFH"
      },
      "outputs": [],
      "source": [
        "waveform,label= test_dl.dataset[12]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUg9zOkbAo6-"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(waveform, rate=22050)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnqTp_twAtH7"
      },
      "outputs": [],
      "source": [
        "wav= torch.unsqueeze(waveform, dim=0)\n",
        "cnn.to(device)\n",
        "wav =wav.to(device)\n",
        "out = cnn(wav)\n",
        "pred= out.argmax(dim=-1).flatten()\n",
        "classes[pred], classes[label]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 1**"
      ],
      "metadata": {
        "id": "zL9kGi-XMsz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder"
      ],
      "metadata": {
        "id": "tASY5tzYMsz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder.\n",
        "        self.enc_conv1 = nn.Conv2d(n_input, n_channel, kernel_size=3, padding = 1, stride = 16)       # entra =>  input x 1     sale =>   input x n_channel\n",
        "        self.pool1 = nn.MaxPool2d(4)                                                                  #                         sale =>   input/2 x n_channel\n",
        "        self.enc_conv2 = nn.Conv2d(n_channel, n_channel*2, kernel_size=3, padding = 1, stride = 1)    #                         sale =>   input/2 x n_channel*2\n",
        "        self.pool2 = nn.MaxPool2d(2)                                                                  #                         sale =>   input/4 x n_channel*2\n",
        "        self.enc_conv3 = nn.Conv2d(n_channel*2, n_channel*2, kernel_size=3, padding = 1, stride = 1)  #                         sale =>   input/4 x n_channel*2\n",
        "\n",
        "        # Decoder.\n",
        "        self.dec_conv1 = nn.ConvTranspose2d(n_channel*2, n_channel*2, kernel_size=20, stride = 4)      # entra =>  input/4 x n_channel*2 sale =>  input/2 x n_channel*2\n",
        "        self.dec_conv2 = nn.ConvTranspose2d(n_channel*2, n_channel, kernel_size=20, stride = 2)        #                                 sale =>  input x n_channel\n",
        "        self.dec_conv3 = nn.ConvTranspose2d(n_channel, n_input, kernel_size=3, stride = 16,padding = 1)#                                 sale =>  input x 1\n",
        "\n",
        "        # misma cantidad de capas convoluciones entre el encoder y el decoder, sin pooling. la salida del encoder tiene que ser igual al input del encoder.\n",
        "        # la cantidad de capas puede variar siempre y cuando se respeten los tamaños de entrada.\n",
        "\n",
        "    def forward_encoder(self, x):\n",
        "        x = F.relu(self.enc_conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.enc_conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.enc_conv3(x))\n",
        "        return x\n",
        "\n",
        "    def forward_decoder(self, x):\n",
        "        x = F.relu(self.dec_conv1(x))\n",
        "        x = F.relu(self.dec_conv2(x))\n",
        "        x = torch.sigmoid(self.dec_conv3(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_encoder(x)\n",
        "        x = self.forward_decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "autoencoder = Autoencoder(n_input=1, n_output=len(classes)).to(device)\n",
        "\n",
        "# # Dummy input for testing\n",
        "# audio_size = [1, 110250]\n",
        "# dummy_input = torch.rand(audio_size).to(device)\n",
        "# output = autoencoder(dummy_input)\n",
        "# print(output.size())\n",
        "# print(autoencoder)\n"
      ],
      "metadata": {
        "id": "2_us-BjcMsz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamos autoencoder"
      ],
      "metadata": {
        "id": "ayEJjPtyYyiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.SGD(autoencoder.parameters(), lr = 0.01, momentum = 0.9)"
      ],
      "metadata": {
        "id": "d91usUONZahI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "\n",
        "  for data in train_dl:\n",
        "    audio,spectogram, mel_spectogram, labels = data\n",
        "    audio = audio.to(device)\n",
        "    outputs = autoencoder(audio)\n",
        "    loss = criterion(outputs, audio) # Comparamos la imagen reconstruida con la original.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item() * audio.size(0))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data_val in valid_dl:\n",
        "      audio_val,spectogram_val, mel_spectogram_val, labels_val = data_val\n",
        "      audio_val = audio_val.to(device)\n",
        "      outputs_val = autoencoder(audio_val)\n",
        "      loss_val = criterion(outputs_val, audio_val)\n",
        "      val_loss.append(loss_val.item() * audio_val.size(0))\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Train Loss: {np.mean(train_loss):.4f}, Val Loss: {np.mean(val_loss):.4f}')"
      ],
      "metadata": {
        "id": "Yfb_y2-pYyAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(train_dl)\n",
        "audio,spectogram, mel_spectogram, labels = next(train_iter)\n",
        "audio = audio.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = autoencoder(audio)\n",
        "    latent_space = autoencoder.forward_encoder(audio)\n",
        "\n",
        "audio = audio.cpu().numpy()\n",
        "outputs = outputs.cpu().numpy()\n",
        "\n",
        "num_audio = 5\n",
        "for i in range(num_audio):\n",
        "    original_image = np.transpose(audio[i], (1, 2, 0))\n",
        "    reconstructed_image = np.transpose(outputs[i], (1, 2, 0))\n",
        "\n",
        "    # Mostramos la imagen original.\n",
        "    plt.figure(figsize = (9, 2))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(original_image, interpolation = 'none')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    # Mostramos la imagen reconstruida.\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(reconstructed_image, interpolation = 'none')\n",
        "    plt.title('Reconstructed Image')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(latent_space[i].shape)\n",
        "    print(latent_space[i].view(1, -1))"
      ],
      "metadata": {
        "id": "weEzhez_Y4Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNet"
      ],
      "metadata": {
        "id": "srQHB9WrNEbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class encoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.conv = conv_block(in_c, out_c)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "        return x, p\n",
        "\n",
        "class decoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(out_c+out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        ##print(x.shape, skip.shape)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "    # def forward(self, inputs, skip):\n",
        "    #     x = self.up(inputs)\n",
        "    #     # Ajuste de dimensiones\n",
        "    #     diffY = skip.size()[2] - x.size()[2]\n",
        "    #     diffX = skip.size()[3] - x.size()[3]\n",
        "\n",
        "    #     x = F.pad(x, [diffX // 2, diffX - diffX // 2,\n",
        "    #                   diffY // 2, diffY - diffY // 2])\n",
        "    #     x = torch.cat([x, skip], axis=1)\n",
        "    #     x = self.conv(x)\n",
        "    #     return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        self.e1 = encoder_block(1, 16)\n",
        "        self.e2 = encoder_block(16, 32)\n",
        "        self.e3 = encoder_block(32, 64)\n",
        "        self.e4 = encoder_block(64, 128)\n",
        "\n",
        "        # self.e1 = encoder_block(256, 128)\n",
        "        # self.e2 = encoder_block(128, 64)\n",
        "        # self.e3 = encoder_block(64, 32)\n",
        "        # self.e4 = encoder_block(32, 16)\n",
        "\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        #self.b = conv_block(16, 32)\n",
        "        self.b = conv_block(128, 256)\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        self.d1 = decoder_block(256, 128)\n",
        "        self.d2 = decoder_block(128, 64)\n",
        "        self.d3 = decoder_block(64, 32)\n",
        "        self.d4 = decoder_block(32, 16)\n",
        "\n",
        "        # self.d1 = decoder_block(32, 64)\n",
        "        # self.d2 = decoder_block(64, 128)\n",
        "        # self.d3 = decoder_block(128, 256)\n",
        "        # self.d4 = decoder_block(256, 512)\n",
        "\n",
        "        \"\"\" Classifier \"\"\"\n",
        "        self.outputs = nn.Conv2d(16, 1, kernel_size=1, padding=0)\n",
        "\n",
        "    # def encode(self, inputs):\n",
        "    #     \"\"\" Encoder \"\"\"\n",
        "    #     #print(\"I\", inputs.shape)\n",
        "    #     s1, p1 = self.e1(inputs)\n",
        "    #     #print(\"E1\", s1.shape, p1.shape)\n",
        "    #     s2, p2 = self.e2(p1)\n",
        "    #     #print(\"E2\", s2.shape, p2.shape)\n",
        "    #     s3, p3 = self.e3(p2)\n",
        "    #     #print(\"E3\", s3.shape, p3.shape)\n",
        "    #     s4, p4 = self.e4(p3)\n",
        "    #     #print(\"E4\", s4.shape, p4.shape)\n",
        "\n",
        "\n",
        "    #     return p4, (s1, s2, s3, s4)\n",
        "\n",
        "    # def decode(self, inputs, skips):\n",
        "    #     \"\"\" Decoder \"\"\"\n",
        "    #     #print(\"D\", inputs.shape, skips[3].shape)\n",
        "    #     d1 = self.d1(inputs, skips[3])\n",
        "    #     #print(\"D1\", d1.shape, skips[2].shape)\n",
        "    #     d2 = self.d2(d1, skips[2])\n",
        "    #     #print(\"D2\", d2.shape, skips[1].shape)\n",
        "    #     d3 = self.d3(d2, skips[1])\n",
        "    #     #print(\"D3\", d3.shape, skips[0].shape)\n",
        "    #     d4 = self.d4(d3, skips[0])\n",
        "    #     #print(\"D4\", d4.shape)\n",
        "\n",
        "\n",
        "    #     return d4\n",
        "    # def forward(self, inputs):\n",
        "    #     \"\"\" Encoder \"\"\"\n",
        "    #     p4, (s1, s2, s3, s4) = self.encode(inputs)\n",
        "    #     \"\"\" Bottleneck \"\"\"\n",
        "    #     b = self.b(p4)\n",
        "    #     \"\"\" Decoder \"\"\"\n",
        "    #     d4 = self.decode(b, (s1, s2, s3, s4))\n",
        "    #     \"\"\" Classifier \"\"\"\n",
        "    #     outputs = self.outputs(d4)\n",
        "    #     # #print(outputs.shape)\n",
        "    #     return outputs\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Encoder \"\"\"\n",
        "        s1, p1 = self.e1(inputs)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "        \"\"\" Bottleneck \"\"\"\n",
        "        b = self.b(p4)\n",
        "        \"\"\" Decoder \"\"\"\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "        \"\"\" Classifier \"\"\"\n",
        "        outputs = self.outputs(d4)\n",
        "        # #print(outputs.shape)\n",
        "        return outputs\n",
        "\n",
        "model = UNet().to(device)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "n = count_parameters(model)\n",
        "print(\"Number of parameters: %s\" % n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gYWaW8hNHy9",
        "outputId": "ac993eae-9088-409a-95be-65777bf1f6a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 1943761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### entrenamos y evaluamos UNet"
      ],
      "metadata": {
        "id": "aGV5RsFGWksV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "elif torch.backends.mps.is_available():\n",
        "    torch.mps.empty_cache()\n",
        "\n",
        "gc.collect() # importante para ir liberando memoria ram\n",
        "\n",
        "val_loss = 0\n",
        "val_acc = 0\n",
        "train_acc = 0\n",
        "\n",
        "lr = 0.0001\n",
        "\n",
        "# Loss function is pixel wise\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.5)\n",
        "\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "\n",
        "valid_accs = []\n",
        "num_epochs = 30\n",
        "\n",
        "log = False\n",
        "\n",
        "\n",
        "if log:\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=f\"{model.__class__.__name__}_lr={lr}_bs={batch_size}_epochs={num_epochs},{device}\",\n",
        "    )\n",
        "\n",
        "# IPython clear cell output\n",
        "# IPython.display.clear_output()\n",
        "\n",
        "iterator = tqdm(range(num_epochs), total=num_epochs, desc=\"Epoch\")\n",
        "\n",
        "for epoch in iterator:\n",
        "    train_losses_itter = []\n",
        "\n",
        "    total = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    # Train\n",
        "    model.train()\n",
        "    for wav, _, spectogram, genre_index in train_dl:\n",
        "        #print(spectogram.shape)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        spectogram = spectogram.to(device)#.squeeze(1)\n",
        "        #print(spectogram.shape)\n",
        "\n",
        "        # Spectogram is Batched [10, 1, 256, 256]\n",
        "        # Squeeze to [10, 256, 256]\n",
        "        # Unsqueeze to [10, 256, 256, 1]\n",
        "        #spectogram = spectogram.squeeze(1).unsqueeze(3)\n",
        "\n",
        "        #print(spectogram.shape)\n",
        "        #genre_index = torch.as_tensor(genre_index).to(device)\n",
        "\n",
        "        # Forward\n",
        "        out = model(spectogram)\n",
        "\n",
        "        # MODEL UNET, loss function\n",
        "        loss = loss_function(out.squeeze().reshape(spectogram.shape), spectogram)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses_itter.append(loss.item())\n",
        "\n",
        "        pred = out.argmax(dim=-1).flatten()\n",
        "        train_correct = 0\n",
        "\n",
        "        total += len(pred)\n",
        "        train_acc = 100 * train_correct / total\n",
        "\n",
        "        del spectogram #importante para ir liberando memoria ram\n",
        "        del genre_index #importante para ir liberando memoria ram\n",
        "        del loss #importante para ir liberando memoria ram\n",
        "        del out  #importante para ir liberando memoria ram\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        elif torch.backends.mps.is_available():\n",
        "            torch.mps.empty_cache()\n",
        "\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "\n",
        "        iterator.set_postfix_str(\n",
        "            {\n",
        "                \"Train loss\": round(np.mean(train_losses_itter), 4),\n",
        "                \"Train accuracy\": round(train_acc, 4),\n",
        "                \"Valid loss\": round(val_loss, 4),\n",
        "                \"Valid accuracy\": round(val_acc, 4),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        train_losses.append(np.mean(train_losses_itter))\n",
        "        valid_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        valid_accs.append(val_acc)\n",
        "\n",
        "    #print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    val_losses_itter = []\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    for wav, _, spectogram, genre_index in valid_dl:\n",
        "        #print(wav, genre, index)\n",
        "        spectogram = spectogram.to(device)\n",
        "        #spectogram = spectogram.squeeze(1).unsqueeze(3)\n",
        "\n",
        "        out = model(spectogram)\n",
        "\n",
        "        loss = loss_function(out.squeeze().reshape(spectogram.shape), spectogram)\n",
        "\n",
        "        val_losses_itter.append(loss.item())\n",
        "\n",
        "        pred = out.argmax(dim=-1).flatten()\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        del spectogram\n",
        "        del genre_index\n",
        "        del loss\n",
        "        del out\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        elif torch.backends.mps.is_available():\n",
        "            torch.mps.empty_cache()\n",
        "\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "    #accuracy = correct / len(valid_dl.dataset)\n",
        "    val_acc = 100 * correct / len(valid_dl.dataset)\n",
        "    val_loss = np.mean(val_losses_itter)\n",
        "\n",
        "    #print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, val_loss, accuracy))\n",
        "\n",
        "\n",
        "    iterator.set_postfix_str(\n",
        "        {\n",
        "            \"Train loss\": round(np.mean(train_losses)),\n",
        "            \"Train accuracy\": round(train_acc),\n",
        "            \"Valid loss\": round(val_loss),\n",
        "            \"Valid accuracy\": round(val_acc),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if log:\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"Train loss\": np.mean(train_losses),\n",
        "                \"Train accuracy\": train_acc,\n",
        "                \"Valid loss\": val_loss,\n",
        "                \"Valid accuracy\": val_acc,\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "if log:\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heMxKhxVOvWL",
        "outputId": "4918e03c-56c4-4631-eb98-7364079424b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:   0%|          | 0/30 [00:29<?, ?it/s, {'Train loss': 2391.12, 'Train accuracy': 0.0, 'Valid loss': 0, 'Valid accuracy': 0}]  /usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:   3%|▎         | 1/30 [00:31<15:25, 31.91s/it, {'Train loss': 2452, 'Train accuracy': 0, 'Valid loss': 1264, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:   3%|▎         | 1/30 [00:56<15:25, 31.91s/it, {'Train loss': 1442.1729, 'Train accuracy': 0.0, 'Valid loss': 1263.5907, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:   7%|▋         | 2/30 [00:59<13:47, 29.55s/it, {'Train loss': 2116, 'Train accuracy': 0, 'Valid loss': 375, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:   7%|▋         | 2/30 [01:25<13:47, 29.55s/it, {'Train loss': 496.3089, 'Train accuracy': 0.0, 'Valid loss': 375.1781, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  10%|█         | 3/30 [01:28<13:02, 28.99s/it, {'Train loss': 1589, 'Train accuracy': 0, 'Valid loss': 29, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  10%|█         | 3/30 [01:54<13:02, 28.99s/it, {'Train loss': 268.5553, 'Train accuracy': 0.0, 'Valid loss': 28.9321, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  13%|█▎        | 4/30 [02:03<13:42, 31.64s/it, {'Train loss': 1288, 'Train accuracy': 0, 'Valid loss': 9, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  13%|█▎        | 4/30 [02:28<13:42, 31.64s/it, {'Train loss': 194.6046, 'Train accuracy': 0.0, 'Valid loss': 9.0606, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  17%|█▋        | 5/30 [02:31<12:35, 30.20s/it, {'Train loss': 1065, 'Train accuracy': 0, 'Valid loss': 8, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  17%|█▋        | 5/30 [03:02<12:35, 30.20s/it, {'Train loss': 214.8013, 'Train accuracy': 0.0, 'Valid loss': 7.9061, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  20%|██        | 6/30 [03:05<12:35, 31.48s/it, {'Train loss': 929, 'Train accuracy': 0, 'Valid loss': 8, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  20%|██        | 6/30 [03:34<12:35, 31.48s/it, {'Train loss': 191.5053, 'Train accuracy': 0.0, 'Valid loss': 7.7263, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  23%|██▎       | 7/30 [03:40<12:27, 32.52s/it, {'Train loss': 816, 'Train accuracy': 0, 'Valid loss': 6, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  23%|██▎       | 7/30 [04:14<12:27, 32.52s/it, {'Train loss': 128.8504, 'Train accuracy': 0.0, 'Valid loss': 5.7201, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  27%|██▋       | 8/30 [04:19<12:46, 34.84s/it, {'Train loss': 725, 'Train accuracy': 0, 'Valid loss': 5, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  27%|██▋       | 8/30 [04:44<12:46, 34.84s/it, {'Train loss': 191.4818, 'Train accuracy': 0.0, 'Valid loss': 5.297, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  30%|███       | 9/30 [04:47<11:23, 32.53s/it, {'Train loss': 663, 'Train accuracy': 0, 'Valid loss': 9, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  30%|███       | 9/30 [05:12<11:23, 32.53s/it, {'Train loss': 166.2748, 'Train accuracy': 0.0, 'Valid loss': 9.2467, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  33%|███▎      | 10/30 [05:16<10:31, 31.59s/it, {'Train loss': 618, 'Train accuracy': 0, 'Valid loss': 6, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  33%|███▎      | 10/30 [05:43<10:31, 31.59s/it, {'Train loss': 170.0061, 'Train accuracy': 0.0, 'Valid loss': 5.5611, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  37%|███▋      | 11/30 [05:46<09:49, 31.01s/it, {'Train loss': 575, 'Train accuracy': 0, 'Valid loss': 5, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  37%|███▋      | 11/30 [06:12<09:49, 31.01s/it, {'Train loss': 171.0623, 'Train accuracy': 0.0, 'Valid loss': 4.9472, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  40%|████      | 12/30 [06:16<09:12, 30.70s/it, {'Train loss': 540, 'Train accuracy': 0, 'Valid loss': 7, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  40%|████      | 12/30 [06:41<09:12, 30.70s/it, {'Train loss': 176.0905, 'Train accuracy': 0.0, 'Valid loss': 6.8763, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  43%|████▎     | 13/30 [06:44<08:25, 29.75s/it, {'Train loss': 516, 'Train accuracy': 0, 'Valid loss': 4, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  43%|████▎     | 13/30 [07:11<08:25, 29.75s/it, {'Train loss': 180.7552, 'Train accuracy': 0.0, 'Valid loss': 3.7095, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  47%|████▋     | 14/30 [07:15<08:04, 30.27s/it, {'Train loss': 491, 'Train accuracy': 0, 'Valid loss': 10, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  47%|████▋     | 14/30 [07:40<08:04, 30.27s/it, {'Train loss': 183.2828, 'Train accuracy': 0.0, 'Valid loss': 10.3115, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  50%|█████     | 15/30 [07:43<07:23, 29.56s/it, {'Train loss': 471, 'Train accuracy': 0, 'Valid loss': 3, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  50%|█████     | 15/30 [08:10<07:23, 29.56s/it, {'Train loss': 212.6975, 'Train accuracy': 0.0, 'Valid loss': 2.8935, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  53%|█████▎    | 16/30 [08:14<06:58, 29.92s/it, {'Train loss': 453, 'Train accuracy': 0, 'Valid loss': 3, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  53%|█████▎    | 16/30 [08:38<06:58, 29.92s/it, {'Train loss': 160.7973, 'Train accuracy': 0.0, 'Valid loss': 2.5017, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  57%|█████▋    | 17/30 [08:42<06:20, 29.28s/it, {'Train loss': 436, 'Train accuracy': 0, 'Valid loss': 2, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  57%|█████▋    | 17/30 [09:11<06:20, 29.28s/it, {'Train loss': 228.5689, 'Train accuracy': 0.0, 'Valid loss': 2.1723, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  60%|██████    | 18/30 [09:15<06:05, 30.43s/it, {'Train loss': 422, 'Train accuracy': 0, 'Valid loss': 3, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  60%|██████    | 18/30 [09:52<06:05, 30.43s/it, {'Train loss': 161.0962, 'Train accuracy': 0.0, 'Valid loss': 2.5633, 'Valid accuracy': 0.0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  63%|██████▎   | 19/30 [09:56<06:10, 33.64s/it, {'Train loss': 408, 'Train accuracy': 0, 'Valid loss': 3, 'Valid accuracy': 0}]/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (256) may be set too high. Or, the value for `n_freqs` (256) may be set too low.\n",
            "  warnings.warn(\n",
            "Epoch:  63%|██████▎   | 19/30 [10:14<06:10, 33.64s/it, {'Train loss': 181.8817, 'Train accuracy': 0.0, 'Valid loss': 3.0277, 'Valid accuracy': 0.0}]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, spectogram, mel_spectogram, label = next(iter(train_dl))\n",
        "spec = mel_spectogram.to(device)\n",
        "model.eval()\n",
        "out = model(spec)\n",
        "out.shape\n",
        "# Waveform from mel spectogram\n",
        "waveform, spectogram, mel_spectogram, label = dataset[np.random.randint(len(dataset))]"
      ],
      "metadata": {
        "id": "mJ-v8FsqP5g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spec = mel_spectogram.to(device)\n",
        "model.eval()\n",
        "rec_spec = model(spec).to('cpu').squeeze(0).detach()\n",
        "mel_spectogram = mel_spectogram.squeeze(0).detach().cpu()\n",
        "print(\"waveform\", waveform.shape)\n",
        "print(\"spectogram\", spectogram.shape)\n",
        "print(\"mel_spectogram\", mel_spectogram.shape)\n",
        "\n",
        "print(\"rec_spec\", rec_spec.shape)\n",
        "\n",
        "hop_length=432\n",
        "n_mels=256\n",
        "n_fft = 2*(n_mels - 1)\n",
        "\n",
        "waveform_out = torchaudio.transforms.GriffinLim(n_fft=n_fft, hop_length=hop_length)(rec_spec)\n",
        "waveform = waveform.squeeze(0)\n",
        "print(\"waveform_out\", waveform_out.shape)\n",
        "print(\"waveform\", waveform.shape)\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(20, 5))\n",
        "\n",
        "axs[0, 0].plot(waveform.t().numpy())\n",
        "axs[0, 0].set_title(\"Original Waveform\")\n",
        "\n",
        "axs[0, 1].plot(waveform_out.t().numpy())\n",
        "axs[0, 1].set_title(\"Reconstructed Waveform\")\n",
        "\n",
        "axs[1, 0].imshow(mel_spectogram.log2()[0,:,:].numpy(), cmap='magma')\n",
        "axs[1, 0].set_title(\"Original Spectogram\")\n",
        "\n",
        "axs[1, 1].imshow(rec_spec.squeeze().detach().cpu().numpy(), cmap='magma')\n",
        "axs[1, 1].set_title(\"Reconstructed Spectogram\")\n",
        "\n",
        "#IPython.display.Audio(waveform_out.squeeze(), rate=22050)\n",
        "\n",
        "print(waveform.shape, waveform_out.shape, mel_spectogram.shape, rec_spec.shape)\n",
        "IPython.display.Audio(waveform, rate=samplerate)"
      ],
      "metadata": {
        "id": "zunld4brQSar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Audio(waveform_out, rate=samplerate)"
      ],
      "metadata": {
        "id": "z9siS0tzMsz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert mel_spectogram to waveform\n",
        "waveform, spectogram, mel_spectogram, label = dataset[np.random.randint(len(dataset))]\n",
        "\n",
        "og_waveform = waveform\n",
        "\n",
        "n_fft = 1024\n",
        "hop_length=150\n",
        "n_mels=256\n",
        "\n",
        "f_spec = torchaudio.transforms.Spectrogram(n_fft=n_fft, hop_length=hop_length)\n",
        "griffin_lim = torchaudio.transforms.GriffinLim(n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "spec = f_spec(waveform)\n",
        "\n",
        "rec_waveform = griffin_lim(spec)\n",
        "\n",
        "print(\"Waveform: {}\\n\".format(waveform))\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(20, 5))\n",
        "\n",
        "axs[0, 0].plot(waveform.t().numpy())\n",
        "axs[0, 0].set_title(\"Original Waveform\")\n",
        "\n",
        "axs[0, 1].plot(rec_waveform.t().numpy())\n",
        "axs[0, 1].set_title(\"Reconstructed Waveform\")\n",
        "\n",
        "axs[1, 0].imshow(spec.log2()[0,:,:].numpy(), cmap='magma')\n",
        "axs[1, 0].set_title(\"Original Spectogram\")\n",
        "\n",
        "axs[1, 1].imshow(f_spec(rec_waveform).log2()[0,:,:].numpy(), cmap='magma')\n",
        "axs[1, 1].set_title(\"Reconstructed Spectogram\")\n",
        "\n",
        "print(spec.shape)\n",
        "print(waveform.shape)\n",
        "print(rec_waveform.shape)\n",
        "\n",
        "IPython.display.Audio(torch.cat([waveform, rec_waveform], axis=1), rate=22050)"
      ],
      "metadata": {
        "id": "Jw1mDhskQW7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert mel_spectogram to waveform\n",
        "waveform, spectogram, mel_spectogram, label = dataset[np.random.randint(len(dataset))]\n",
        "\n",
        "og_waveform = waveform\n",
        "\n",
        "hop_length=432\n",
        "n_mels=256\n",
        "n_fft = 2*(n_mels - 1)\n",
        "\n",
        "f_spec = torchaudio.transforms.MelSpectrogram(sample_rate=samplerate, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "\n",
        "griffin_lim = torchaudio.transforms.GriffinLim(n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "spec = f_spec(waveform)\n",
        "\n",
        "rec_waveform = griffin_lim(spec)\n",
        "\n",
        "print(\"Waveform: {}\\n\".format(waveform))\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(20, 5))\n",
        "\n",
        "axs[0, 0].plot(waveform.t().numpy())\n",
        "axs[0, 0].set_title(\"Original Waveform\")\n",
        "\n",
        "axs[0, 1].plot(rec_waveform.t().numpy())\n",
        "axs[0, 1].set_title(\"Reconstructed Waveform\")\n",
        "\n",
        "axs[1, 0].imshow(spec.log2()[0,:,:].numpy(), cmap='magma')\n",
        "axs[1, 0].set_title(\"Original Spectogram\")\n",
        "\n",
        "axs[1, 1].imshow(f_spec(rec_waveform).log2()[0,:,:].numpy(), cmap='magma')\n",
        "axs[1, 1].set_title(\"Reconstructed Spectogram\")\n",
        "\n",
        "print(spec.shape)\n",
        "print(waveform.shape)\n",
        "print(rec_waveform.shape)\n",
        "\n",
        "IPython.display.Audio(torch.cat([waveform, rec_waveform], axis=1), rate=22050)"
      ],
      "metadata": {
        "id": "5eaHFLkhQZul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ex_spec = f_spec(og_waveform)\n",
        "new_spec = f_spec(rec_waveform)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "axs[0].imshow(ex_spec.log2()[0,:,:].numpy(),cmap='magma')\n",
        "axs[0].set_title(\"Original Spectogram\")\n",
        "\n",
        "axs[1].imshow(new_spec.log2()[0,:,:].numpy(),cmap='magma')\n",
        "axs[1].set_title(\"Reconstructed Spectogram\")\n",
        "\n",
        "ex_spec.shape"
      ],
      "metadata": {
        "id": "UTIMsUu4QdQE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "yXnHDpoYttX8",
        "uFwYdlWxCN0M"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}