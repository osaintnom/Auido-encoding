{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1iLx2DRitxx"
      },
      "source": [
        "Universidad Torcuato Di Tella\n",
        "\n",
        "Licenciatura en Tecnología Digital\\\n",
        "**Tecnología Digital VI: Inteligencia Artificial**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSdBL2673KUX",
        "outputId": "fcdcf540-d901-4a65-8868-92c253f0938f"
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio\n",
        "!pip install  pydub\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import tarfile\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAR3tiGci2-e"
      },
      "source": [
        "\n",
        "# TP3: Encodeador de música\n",
        "\n",
        "\n",
        "\n",
        "## Orden de pasos\n",
        "\n",
        "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
        "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
        "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "3. Visualización de los archivos\n",
        "4. Clasificación\n",
        "5. Evaluación\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt4FEe853KUX"
      },
      "outputs": [],
      "source": [
        "project_name='Music_genre_classification'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU5G8mTE-5zM"
      },
      "source": [
        "### 2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5AUydgIxfwi",
        "outputId": "fdb3e6c7-a426-4231-9312-fa3d1e1dd711"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYLOe3isiV0b"
      },
      "source": [
        "data_dir es el path donde pusimos la carpeta genres. \"'//content/drive/MyDrive/Materias/TD6 - Inteligencia Artificial/TPs/2023/TP4/genres/'\" es un ejemplo. Modificar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kYMlPdYrzCi",
        "outputId": "34c72dba-5a51-4321-a417-28e8319378e4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_dir='//content/drive/MyDrive/genres_5sec/'\n",
        "list_files=os.listdir(data_dir)\n",
        "classes=[]\n",
        "for file in list_files:\n",
        "  name='{}/{}'.format(data_dir,file)\n",
        "  if os.path.isdir(name):\n",
        "    classes.append(file)\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJxZV04XZtnP"
      },
      "outputs": [],
      "source": [
        "samplerate=22050\n",
        "def parse_genres(fname):\n",
        "    parts = fname.split('/')[-1].split('.')[0]\n",
        "    return parts #' '.join(parts[0])\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.files =[]\n",
        "        for c in classes:\n",
        "          self.files = self.files + [fname for fname in os.listdir(os.path.join(root,c)) if fname.endswith('.wav')]\n",
        "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
        "        #self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        fname = self.files[i]\n",
        "\n",
        "        #img = self.transform(open_image(fpath))\n",
        "        genre = parse_genres(fname)\n",
        "        fpath = os.path.join(self.root,genre, fname)\n",
        "        class_idx = self.classes.index(genre)\n",
        "        audio = torchaudio.load(fpath)[0]\n",
        "\n",
        "        return audio, class_idx\n",
        "dataset = MusicDataset(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDBqRCWT0p8j"
      },
      "source": [
        "### 3. Visualización de los archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiDa813SG-2f",
        "outputId": "ebe04ddf-bd01-49f4-aafe-6ff7827196ad"
      },
      "outputs": [],
      "source": [
        "waveform,label= dataset[0]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))\n",
        "# label = 9 es rock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_MA3RlaDG-0A",
        "outputId": "fa62a4b1-a5f1-4a04-9580-f3022cca21ff"
      },
      "outputs": [],
      "source": [
        "specgram=tt.Spectrogram()(waveform)\n",
        "print(\"shape of spectogram {}\".format(specgram.size()))\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(specgram.log2()[0,:,:].numpy(),cmap='magma')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "xHdITZUAzQYG",
        "outputId": "0383a6dd-b32c-4d18-96b0-cad7f4cd0af8"
      },
      "outputs": [],
      "source": [
        "print(\"Waveform: {}\\n\".format(waveform))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(waveform.t().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEFLn0DAK4Y4"
      },
      "source": [
        "Escuchamos el espectograma con la librería de audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "kLwAcRJ155pl",
        "outputId": "b057620b-c7c3-4254-c384-4feb4fd4c6de"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(waveform,rate=samplerate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcCdQJS8G-pX",
        "outputId": "6ac4b0ce-bdaa-4f2a-d856-37f604da2ead"
      },
      "outputs": [],
      "source": [
        "specgram.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dr5Qhgk5sjL",
        "outputId": "8896a706-7327-4a41-dd42-531000c768e6"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed);\n",
        "val_size = 100\n",
        "test_size = 100\n",
        "train_size = len(dataset) - val_size - test_size\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "len(train_ds),len(val_ds),len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBHjbBoo5sG1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 20\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds,1, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXnHDpoYttX8"
      },
      "source": [
        "### 4. Clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkfBRO910vu3"
      },
      "outputs": [],
      "source": [
        "class M5(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(4)\n",
        "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool2 = nn.MaxPool1d(4)\n",
        "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool3 = nn.MaxPool1d(4)\n",
        "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
        "        self.pool4 = nn.MaxPool1d(4)\n",
        "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(self.bn2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = F.relu(self.bn3(x))\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = F.relu(self.bn4(x))\n",
        "        x = self.pool4(x)\n",
        "        x = F.avg_pool1d(x, x.shape[-1])\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryss1Hhm3KUf",
        "outputId": "5b2a9b75-cfef-4836-ebd4-c2f5801d62ab"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "cnn = M5(n_input=1, n_output=len(classes))\n",
        "cnn.to(device)\n",
        "print(cnn)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "n = count_parameters(cnn)\n",
        "print(\"Number of parameters: %s\" % n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTnjUZU_3oou",
        "outputId": "6433690d-d1bc-406f-e4ca-9646d0a454e2"
      },
      "outputs": [],
      "source": [
        "len(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cJrYPk8V8J",
        "outputId": "1b6d205a-4038-444f-c00a-70659035755d"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0005)\n",
        "valid_losses = []\n",
        "num_epochs = 30\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect() #importante para ir liberando memoria ram\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "\n",
        "    # Train\n",
        "    cnn.train()\n",
        "    for wav, genre_index in train_dl:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        wav=wav.to(device)\n",
        "        genre_index =torch.as_tensor(genre_index).to(device)\n",
        "\n",
        "        # Forward\n",
        "        out = cnn(wav)\n",
        "        #M5\n",
        "        loss = F.nll_loss(out.squeeze(), genre_index)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        del wav #importante para ir liberando memoria ram\n",
        "        del genre_index #importante para ir liberando memoria ram\n",
        "        del loss #importante para ir liberando memoria ram\n",
        "        del out  #importante para ir liberando memoria ram\n",
        "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
        "\n",
        "    # Validation\n",
        "    cnn.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    losses = []\n",
        "    correct =0\n",
        "    for wav, genre_index in valid_dl:\n",
        "        #print(wav, genre, index)\n",
        "        wav = wav.to(device)\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        out = cnn(wav)\n",
        "        #M5\n",
        "        loss = F.nll_loss(out.squeeze(), genre_index)\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        #M5\n",
        "        pred= out.argmax(dim=-1).flatten()\n",
        "        # append labels and predictions\n",
        "        correct += pred.eq(genre_index).sum().item()\n",
        "        y_true.extend(genre_index)\n",
        "        y_pred.extend(pred)\n",
        "        del wav #importante para ir liberando memoria ram\n",
        "        del genre_index #importante para ir liberando memoria ram\n",
        "        del loss #importante para ir liberando memoria ram\n",
        "        del out  #importante para ir liberando memoria ram\n",
        "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
        "        gc.collect() #importante para ir liberando memoria ram\n",
        "\n",
        "    accuracy =correct/ len(valid_dl.dataset)\n",
        "    valid_loss = np.mean(losses)\n",
        "    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n",
        "\n",
        "    # Save model\n",
        "    valid_losses.append(valid_loss.item())\n",
        "    if np.argmin(valid_losses) == epoch:\n",
        "        print('Saving the best model at %d epochs!' % epoch)\n",
        "        torch.save(cnn.state_dict(), 'best_model.ckpt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFwYdlWxCN0M"
      },
      "source": [
        "\n",
        "\n",
        "### 5. Evaluación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6RFD17nU81b"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(test_ds,1,shuffle=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pqtx-D0zAwa",
        "outputId": "78655b08-281f-47aa-cf44-590b8250f747"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "S = torch.load('best_model.ckpt')\n",
        "cnn.load_state_dict(S)\n",
        "print('loaded!')\n",
        "\n",
        "# Run evaluation\n",
        "cnn.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for wav, genre_index in test_dl:\n",
        "        wav = wav.to(device)\n",
        "        genre_index = genre_index.to(device)\n",
        "\n",
        "        out = cnn(wav)\n",
        "\n",
        "        pred= out.argmax(dim=-1).flatten()\n",
        "        # append labels and predictions\n",
        "        correct += pred.eq(genre_index).sum().item()\n",
        "        y_true.extend(genre_index)\n",
        "        y_pred.extend(pred)\n",
        "\n",
        "accuracy =correct/ len(test_dl.dataset)\n",
        "print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA6O4xauAZFH",
        "outputId": "aa2e5a4f-e5ab-4e73-f897-e1187e64527d"
      },
      "outputs": [],
      "source": [
        "waveform,label= test_dl.dataset[12]\n",
        "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "wUg9zOkbAo6-",
        "outputId": "48744014-9451-439d-90ed-9082aa14d76a"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(waveform, rate=22050)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnqTp_twAtH7",
        "outputId": "4ad8f855-ed42-4554-8235-4b0fe31a217e"
      },
      "outputs": [],
      "source": [
        "wav= torch.unsqueeze(waveform, dim=0)\n",
        "cnn.to(device)\n",
        "wav =wav.to(device)\n",
        "out = cnn(wav)\n",
        "pred= out.argmax(dim=-1).flatten()\n",
        "classes[pred], classes[label]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
